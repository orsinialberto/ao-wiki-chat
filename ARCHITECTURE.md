# Architettura WikiChat - Sistema RAG

## Overview
WikiChat Ã¨ un sistema RAG (Retrieval-Augmented Generation) che permette di caricare documenti e porre domande sul loro contenuto. Il sistema combina ricerca vettoriale semantica con un LLM per fornire risposte accurate e contestualizzate.

---

## Stack Tecnologico

- **Backend**: Java 25, Spring Boot 4.x
- **Database**: PostgreSQL 15+ con estensione pgvector
- **LLM & Embeddings**: Google Gemini API (free tier)
- **Framework AI**: LangChain4j
- **Containerizzazione**: Docker & Docker Compose

---

## Architettura a Livelli

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CLIENT (Future: React)                    â”‚
â”‚              - Upload documenti                             â”‚
â”‚              - Chat Interface                               â”‚
â”‚              - Visualizzazione sorgenti                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (Spring Boot)                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚          PRESENTATION LAYER                              â”‚â”‚
â”‚ â”‚  DocumentController | ChatController | HealthController  â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚           SERVICE LAYER                                  â”‚â”‚
â”‚ â”‚  DocumentService | ChunkingService | EmbeddingService    â”‚â”‚
â”‚ â”‚  VectorSearchService | RAGService (orchestrator)         â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚           INTEGRATION LAYER                              â”‚â”‚
â”‚ â”‚  LangChain4j | Gemini API Client | Document Parsers      â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚           DATA LAYER                                     â”‚â”‚
â”‚ â”‚  DocumentRepo | ChunkRepo | ConversationRepo             â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ JPA/JDBC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PostgreSQL + pgvector                          â”‚
â”‚  - Metadata documenti                                       â”‚
â”‚  - Chunks di testo + embeddings vettoriali                  â”‚
â”‚  - Cronologia conversazioni                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Struttura Package

```
com.example.ao_wiki_chat/
â”œâ”€â”€ AoWikiChatApplication.java
â”‚
â”œâ”€â”€ config/                          # Configurazioni
â”‚   â”œâ”€â”€ LangChain4jConfig.java      
â”‚   â”œâ”€â”€ GeminiConfig.java            
â”‚   â”œâ”€â”€ WebConfig.java               # CORS
â”‚   â””â”€â”€ AsyncConfig.java             # Async processing
â”‚
â”œâ”€â”€ controller/                      # REST Controllers
â”‚   â”œâ”€â”€ DocumentController.java      
â”‚   â”œâ”€â”€ ChatController.java          
â”‚   â””â”€â”€ HealthController.java        
â”‚
â”œâ”€â”€ service/                         # Business Logic
â”‚   â”œâ”€â”€ DocumentService.java         
â”‚   â”œâ”€â”€ ChunkingService.java         # Splitting documenti
â”‚   â”œâ”€â”€ EmbeddingService.java        # Generazione embeddings
â”‚   â”œâ”€â”€ VectorSearchService.java     # Ricerca similaritÃ 
â”‚   â”œâ”€â”€ ChatService.java             
â”‚   â””â”€â”€ RAGService.java              # Orchestratore RAG
â”‚
â”œâ”€â”€ integration/                     # Integrazioni esterne
â”‚   â”œâ”€â”€ gemini/
â”‚   â”‚   â”œâ”€â”€ GeminiClient.java        
â”‚   â”‚   â””â”€â”€ GeminiEmbeddingService.java
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ DocumentParser.java      # Interface
â”‚   â”‚   â”œâ”€â”€ MarkdownParser.java
â”‚   â”‚   â”œâ”€â”€ HtmlParser.java
â”‚   â”‚   â””â”€â”€ PdfParser.java
â”‚   â””â”€â”€ langchain/
â”‚       â””â”€â”€ LangChain4jService.java  
â”‚
â”œâ”€â”€ repository/                      # Data Access
â”‚   â”œâ”€â”€ DocumentRepository.java
â”‚   â”œâ”€â”€ ChunkRepository.java
â”‚   â””â”€â”€ ConversationRepository.java
â”‚
â”œâ”€â”€ model/                           # Domain Models
â”‚   â”œâ”€â”€ entity/                      # JPA Entities
â”‚   â”‚   â”œâ”€â”€ Document.java
â”‚   â”‚   â”œâ”€â”€ Chunk.java
â”‚   â”‚   â”œâ”€â”€ Conversation.java
â”‚   â”‚   â””â”€â”€ Message.java
â”‚   â””â”€â”€ dto/                         # Data Transfer Objects
â”‚       â”œâ”€â”€ DocumentUploadRequest.java
â”‚       â”œâ”€â”€ DocumentResponse.java
â”‚       â”œâ”€â”€ ChatRequest.java
â”‚       â”œâ”€â”€ ChatResponse.java
â”‚       â””â”€â”€ SourceReference.java
â”‚
â”œâ”€â”€ exception/                       # Exception Handling
â”‚   â”œâ”€â”€ GlobalExceptionHandler.java
â”‚   â”œâ”€â”€ DocumentProcessingException.java
â”‚   â””â”€â”€ EmbeddingException.java
â”‚
â””â”€â”€ util/                           # Utilities
    â”œâ”€â”€ TextProcessor.java          
    â””â”€â”€ VectorUtils.java            
```

---

## Schema Database PostgreSQL

```sql
-- Estensione pgvector
CREATE EXTENSION IF NOT EXISTS vector;

-- Tabella documenti
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    filename VARCHAR(255) NOT NULL,
    content_type VARCHAR(50) NOT NULL,
    file_size BIGINT NOT NULL,
    upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(20) DEFAULT 'PROCESSING',
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabella chunks (frammenti di testo)
CREATE TABLE chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    chunk_index INTEGER NOT NULL,
    embedding vector(768),  -- Dimensione embedding Gemini
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(document_id, chunk_index)
);

-- Indice per ricerca vettoriale (HNSW)
CREATE INDEX chunks_embedding_idx ON chunks 
USING hnsw (embedding vector_cosine_ops);

-- Tabella conversazioni
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabella messaggi
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL,  -- USER, ASSISTANT
    content TEXT NOT NULL,
    sources JSONB,  -- Riferimenti ai chunks utilizzati
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indici per performance
CREATE INDEX idx_chunks_document_id ON chunks(document_id);
CREATE INDEX idx_messages_conversation_id ON messages(conversation_id);
CREATE INDEX idx_conversations_session_id ON conversations(session_id);
```

---

## Pipeline RAG

### A) INGESTION PIPELINE (Caricamento Documenti)

```
1. Upload Documento (DocumentController)
   â†“
2. Validazione (tipo, dimensione)
   â†“
3. Salvataggio metadata in DB (status: PROCESSING)
   â†“
4. Async Processing:
   â”œâ”€ Parsing (MD/HTML/PDF â†’ testo)
   â”œâ”€ Chunking (split ~500 token con overlap 50)
   â”œâ”€ Generazione Embeddings (Gemini API)
   â””â”€ Salvataggio chunks + embeddings in DB
   â†“
5. Aggiornamento status: COMPLETED/FAILED
```

### B) RETRIEVAL PIPELINE (Query Chat)

```
1. Domanda utente (ChatController)
   â†“
2. Generazione embedding domanda (GeminiEmbeddingService)
   â†“
3. Vector Search su pgvector (VectorSearchService)
   â”œâ”€ Cosine similarity
   â””â”€ Top-k chunks (k=5-10)
   â†“
4. Costruzione prompt con contesto (RAGService)
   â†“
5. Chiamata LLM Gemini (GeminiChatService)
   â†“
6. Salvataggio conversazione in DB
   â†“
7. Risposta + riferimenti sorgenti
```

---

## Flusso Dati RAG Dettagliato

```
[Utente] â†’ "Cos'Ã¨ WikiChat?"
    â†“
[ChatController.processQuery()]
    â†“
[RAGService.processQuery()]
    â”œâ”€ 1. EmbeddingService.generateEmbedding(query)
    â”‚      â””â†’ Gemini API â†’ vector[768]
    â”‚
    â”œâ”€ 2. VectorSearchService.findSimilar(vector)
    â”‚      â””â†’ PostgreSQL pgvector â†’ top 5 chunks
    â”‚
    â”œâ”€ 3. buildContext(chunks)
    â”‚      â””â†’ "Contesto:\n[chunk1]\n[chunk2]..."
    â”‚
    â”œâ”€ 4. buildPrompt(context, query)
    â”‚      â””â†’ "Dato il seguente contesto, rispondi..."
    â”‚
    â”œâ”€ 5. GeminiChatService.generate(prompt)
    â”‚      â””â†’ Gemini API â†’ risposta generata
    â”‚
    â””â”€ 6. saveConversation(...)
           â””â†’ PostgreSQL â†’ messages table

[Risposta] â† { answer, sources[] }
```

---

## Componenti Chiave

### RAGService (Orchestratore)
Il cervello del sistema. Coordina tutte le operazioni:
- Riceve query utente
- Genera embedding della query
- Cerca chunks rilevanti nel database
- Costruisce prompt con contesto
- Chiama LLM per generare risposta
- Salva cronologia conversazione
- Ritorna risposta con sorgenti citate

### VectorSearchService
Gestisce la ricerca semantica:
- Query: `SELECT *, embedding <=> :vector AS distance FROM chunks ORDER BY distance LIMIT k`
- Utilizza operatore `<=>` (cosine distance) di pgvector
- Filtra per similarity threshold (> 0.7)
- Ritorna chunks piÃ¹ rilevanti ordinati per score

### ChunkingService
Intelligente splitting del testo:
- Divide testo in frammenti ~500 token
- Overlap di 50 token tra chunks per continuitÃ 
- Preserva integritÃ  semantica (non spezza frasi)
- Gestisce metadata (numero pagina, sezione, etc.)

### EmbeddingService
Genera rappresentazioni vettoriali:
- Batch processing per efficienza (max 100 chunks)
- Rate limiting per rispettare quota Gemini API
- Retry con exponential backoff su errori
- Caching opzionale per chunks duplicati

---

## Integrazioni Esterne

### Google Gemini API
**Modelli utilizzati**:
- `text-embedding-004`: generazione embeddings (768 dimensioni)
- `gemini-2.0-flash-exp`: generazione risposte chat (latest model)

**Free Tier Limits**:
- 2M token input/giorno
- 32K token/minuto
- Rate limiting gestito con retry automatico

### LangChain4j
Framework per semplificare integrazione LLM:
- Abstraction layer per Gemini API
- Gestione automatica prompt templates
- Streaming responses (opzionale)
- Memory management per conversazioni

---

## ScalabilitÃ  e Performance

### Database Optimization
- **Indice HNSW** su embeddings per ricerca O(log n)
- **Connection pooling** HikariCP (default Spring Boot)
- **Batch inserts** per chunks durante ingestion
- **Prepared statements** per prevenire SQL injection

### Async Processing
- **ThreadPoolTaskExecutor** per processing documenti
- Core pool: 4 thread, Max: 8 thread
- Non blocca endpoint REST durante processing
- Status polling via GET /api/documents/{id}

### Caching Strategy (Future)
- Redis per cache embeddings frequenti
- Cache risultati vector search (TTL: 1h)
- Cache risposte LLM per query identiche

---

## Security (Post-MVP)

### Autenticazione & Autorizzazione
- JWT tokens per autenticazione
- Spring Security integration
- Role-based access control (USER, ADMIN)

### Input Validation
- Whitelisting content-type upload
- Max file size enforcement (50MB)
- Sanitizzazione input utente
- SQL injection prevention (prepared statements)

### Rate Limiting
- Bucket4j per limit requests/user
- Protezione endpoint pubblici
- Monitoraggio usage Gemini API

---

## Monitoring & Logging

### Logging Strategy
```yaml
spring:
  output:
    ansi:
      enabled: ALWAYS  # Colored logs in console

logging:
  level:
    root: INFO
    com.example.ao_wiki_chat: DEBUG
    org.springframework.web: INFO
    org.hibernate.SQL: DEBUG
    org.hibernate.type.descriptor.sql.BasicBinder: TRACE
    dev.langchain4j: DEBUG
  pattern:
    # Colored pattern with blue timestamps, highlighted levels, cyan logger names
    console: "%clr(%d{yyyy-MM-dd HH:mm:ss}){blue} %clr([%5p]){highlight} %clr(%-40.40logger{39}){cyan} : %m%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
```

**Log Colors**:
- ğŸ”´ ERROR in red
- ğŸŸ¡ WARN in yellow
- ğŸŸ¢ INFO in green
- âšª DEBUG in white
- ğŸ”µ Timestamps in blue
- ğŸ”· Logger names in cyan

### Metriche da Monitorare
- Latenza vector search (target: <100ms)
- Tempo generazione embeddings
- Rate limiting Gemini API (token usage)
- Dimensione database chunks
- Numero richieste/secondo

### Health Checks
- `GET /api/health` - application status
- `GET /api/health/db` - PostgreSQL connectivity
- `GET /api/health/gemini` - Gemini API availability

---

## Diagramma ER Database

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  documents   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ id (PK)      â”‚â”€â”€â”
â”‚ filename     â”‚  â”‚
â”‚ content_type â”‚  â”‚
â”‚ status       â”‚  â”‚
â”‚ metadata     â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                  â”‚ 1:N
                  â”‚
               â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   chunks    â”‚
               â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
               â”‚ id (PK)     â”‚
               â”‚ document_id â”‚ (FK)
               â”‚ content     â”‚
               â”‚ embedding   â”‚ â† vector(768)
               â”‚ chunk_index â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ conversations   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ id (PK)         â”‚â”€â”€â”
â”‚ session_id      â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚ 1:N
                     â”‚
                  â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  messages  â”‚
                  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                  â”‚ id (PK)    â”‚
                  â”‚ conv_id    â”‚ (FK)
                  â”‚ role       â”‚
                  â”‚ content    â”‚
                  â”‚ sources    â”‚ â† JSONB
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## API Endpoints

### Documents
```
POST   /api/documents/upload          # Upload documento
GET    /api/documents                 # Lista documenti
GET    /api/documents/{id}            # Dettaglio documento
DELETE /api/documents/{id}            # Elimina documento
GET    /api/documents/{id}/chunks     # Visualizza chunks
```

### Chat
```
POST   /api/chat/query                # Invia domanda
GET    /api/chat/history/{sessionId}  # Cronologia conversazione
DELETE /api/chat/{sessionId}          # Cancella conversazione
```

### Health
```
GET    /api/health                    # Status generale
GET    /api/health/db                 # Check database
GET    /api/health/gemini             # Check Gemini API
```

---

## Decisioni Architetturali

### PerchÃ© pgvector?
- Native PostgreSQL extension
- Performance eccellenti con indice HNSW
- No necessitÃ  di database vettoriale separato
- SemplicitÃ  deployment

### PerchÃ© LangChain4j?
- Abstraction layer per LLM
- Support nativo per Gemini API
- Community attiva, ben documentato
- Facilita switch tra provider LLM

### PerchÃ© Async Processing?
- Upload documenti non blocca endpoint
- User experience migliore (risposta immediata)
- Gestione errori centralizzata
- ScalabilitÃ  (code processing)

### PerchÃ© Chunking con Overlap?
- Evita perdita informazioni ai confini
- Migliora retrieval accuracy
- Context continuity tra chunks
- Best practice RAG systems

---

## Future Enhancements

### Fase 2 (Post-MVP)
- Frontend React completo
- Autenticazione utenti
- Multi-tenancy support
- Caching Redis

### Fase 3 (ScalabilitÃ )
- Kubernetes deployment
- Message queue (RabbitMQ) per processing
- Distributed tracing (Jaeger)
- Metrics dashboard (Grafana)

### Fase 4 (Features Avanzate)
- OCR per immagini in PDF
- Multi-modal embeddings
- Conversational memory
- Query expansion/rewriting

